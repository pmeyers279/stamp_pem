#!/usr/bin/env python

import markup
import optparse
from stamp_pem import coh_io
from gwpy.segments import (DataQualityFlag, SegmentList, Segment)
import numpy as np
import glob
import h5py
#import pdb


def parse_command_line():
    """
    parse command parse command line
    """
    parser = optparse.OptionParser()
    parser.add_option(
        "--ini-file", "-i", help="pipeline ini file",
        default=None, type=str, dest='ini')
    parser.add_option(
        "--tag", "-t",
        help="optional, extra tag for picking out specific plots if necessary",
        default=None,
        type=str, dest="tag")
    parser.add_option(
        "--num-chans-to-combine", dest="nchans", default=20, type=int)
    parser.add_option(
        "-s", "--start-time", dest="st", default=None, type=int)
    parser.add_option(
        "-e", "--end-time", dest="et", default=None, type=int)
    parser.add_option(
        "-l", "--flow", dest="flow", default=None, type=float)
    parser.add_option(
        "-g", "--fhigh", dest="fhigh", default=None, type=float)
    params, args = parser.parse_args()
    return params

params = parse_command_line()

# read out parameters
pipeline_dict = coh_io.read_pipeline_ini(params.ini)
env_params, run_params = coh_io.check_ini_params(pipeline_dict)

# get times
inc = int(env_params['online_increment'])
if params.st is None:
    time_file = env_params['online_time_file']
    st = coh_io.read_time_from_file(time_file)
else:
    st = params.st
if params.et is None:
    et = st + inc
else:
    et = params.et

# get segments
seg_dir = coh_io.get_directory_structure(
    'SEGMENTS', st, env_params['base_directory'])
flag = run_params['flag']
seg_files = sorted(glob.glob('%s/*.xml.gz'%seg_dir))
#seg_file = coh_io.create_coherence_data_filename(flag, 'SEGMENTS', st, et,
#                                                 directory=seg_dir)
segs = SegmentList()
for seg_file in seg_files:
    segments = DataQualityFlag.read(seg_file)
    for segment in segments:
        if segment[0] >= params.st and segment[1] <= params.et:
            segs.append(segment)
#pdb.set_trace()
#segs = DataQualityFlag.read('%s.xml.gz' % seg_file)

# get channels
channels = coh_io.read_list(env_params['list'])
subsystems = channels.keys()
darm = run_params['darm_channel']

# initialize some variables
images = []
data_files = []

# make page
page = markup.page()
page.init(title="Coherence Studies", header="%d - %d" %
          (st, et),
          footer="questions? contact patrick.meyers@ligo.org")
page.div(class_='segments')
page.h3('SEGMENTS ANALYZED')
for seg in segs:
    page.p('%d - %d' % (seg[0].seconds, seg[1].seconds))
page.div.close()
page.p('Data is in hdf5 format. It can be loaded by importing h5py in python \
       <br> >>> from gwpy.spectrum import Spectrum\
       <br> >>> import h5py\
       <br> >>> f = h5py.File(%(filename))\
       <br> >>> data = Spectrum.h5py(f[%(type)][%(channel)])\
       <br>\
       <br> Types are "coherences", "psd1", "psd2s", "csd12s", "info"\
       <br> The channel with which all other channels take coherence\
       <br> is in the title of the filename. The PSD for this channel\
       <br> is psd1. The psd for all other channels is psd2s.\
       <br> The csd for channel1 and all channel2s is in csd12s.\
       <br> Info is the number of time segments used in the analysis.\
       <br> coherences = abs(csd12s)^2 / psd1 * psd2s.\
       <br> coherence SNR (which is plotted) is taken to be N * coherences.'
       )
page.div(class_='thumbs')
First = 1
for subsystem in subsystems:
    chans = []
    for key in channels[subsystem].keys():
        chans.append(channels[subsystem][key])
    njobs = np.ceil(len(chans) / float(params.nchans))
    njobs = int(njobs)
    if First:
	fdir = coh_io.get_directory_structure(subsystem, params.st, directory='../../results2')
	fname2 = coh_io.create_coherence_data_filename(darm, subsystem, params.st, (params.st + 158400), tag=1)
        print fdir
	print fdir+fname2

	f2 = h5py.File(fdir+fname2)
	page.p('%d segments analyzed'%f2['info'].value)
	First = 0
    
    for job in range(njobs):
        file_directory = coh_io.get_directory_structure(
            subsystem, params.st, directory='../../')
        fname_data = coh_io.create_coherence_data_filename(darm,
                                                           subsystem,
                                                           params.st, params.et, tag=job+1,
							   directory=file_directory)
        fname = coh_io.create_coherence_data_filename(
            darm, subsystem, params.st, params.et, tag=job+1, directory=file_directory)
	if params.flow:
            fname = fname + '-' + str(int(params.flow*10)) + '-' + str(int(params.fhigh*10))

        page.img(src=fname + '.png', width=1200, height=600, class_="thumb")
        page.a('<br> Full frequency band data for %s subsystem <br>' %
               subsystem, href=fname_data)

page.div.close()

# save file
output_dir = coh_io.get_directory_structure(
    'HTML', params.st, directory=env_params['base_directory'])
output_fname = coh_io.create_coherence_data_filename(
    darm, 'HTML', params.st, params.et, directory=output_dir)
if params.flow:
    output_fname = output_fname + '-' + str(int(params.flow*10)) + '-' + str(int(params.fhigh*10))
f = open(output_fname + '.html', 'w')
print >> f, page
f.close()
